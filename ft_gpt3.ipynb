{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNDiX0auNTSi+pCB68h6Mk6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MungaiMwangi001/LLMs/blob/main/ft_gpt3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Installing Depedancies**"
      ],
      "metadata": {
        "id": "CR1j-_CnKwSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai fastapi uvicorn pydantic\n"
      ],
      "metadata": {
        "id": "XJg2JzlkKpe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Install OpenAI library and set Api Key**\n",
        "\n",
        "- The OpenAI key is stored in collabs\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "0d8ofvEuKo1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\"\n",
        "client = OpenAI()\n"
      ],
      "metadata": {
        "id": "MvPEcAx6K8tH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prepare the dataset**\n",
        "- Data is stored in jsonl fprmat  for OpenAI\n",
        "- Each line is  a separate  json Object"
      ],
      "metadata": {
        "id": "WmPpKd_W00sk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mRL6KBImwYk"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "data = [\n",
        "    {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"You are a teaching assistant for Machine Learning.\"},\n",
        "            {\"role\": \"user\", \"content\": \"What is machine learning?\"},\n",
        "            {\"role\": \"assistant\", \"content\": \"'Tis but the art of teaching machines to think...\"}\n",
        "        ]\n",
        "    }\n",
        "]\n",
        "\n",
        "with open(\"train.jsonl\", \"w\") as f:\n",
        "    for row in data:\n",
        "        f.write(json.dumps(row) + \"\\n\")\n",
        "print(\"train.jsonl ready\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Upload the file to OpenAI**"
      ],
      "metadata": {
        "id": "SsrSLw410fUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "upload = client.files.create(\n",
        "    file=open(\"train.jsonl\", \"rb\"),\n",
        "    purpose=\"fine-tune\"\n",
        ")\n",
        "print(\"File ID:\", upload.id)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gb2yqTEr0nwN",
        "outputId": "203b85a4-211d-467c-e027-29c53738b46c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FileObject(id='file-EHVfZvuXQ3VFdF56HyBk5x', bytes=245, created_at=1754948566, filename='train.jsonl', object='file', purpose='fine-tune', status='processed', expires_at=None, status_details=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create a fine-tuned model**"
      ],
      "metadata": {
        "id": "dxUS43Ki2nL7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job = client.fine_tuning.jobs.create(\n",
        "    training_file=upload.id,\n",
        "    model=\"gpt-3.5-turbo\"\n",
        ")\n",
        "print(job)\n"
      ],
      "metadata": {
        "id": "PtAbtFgVLQfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Monitor the job**"
      ],
      "metadata": {
        "id": "yoz2sKdL3XcF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "job_id = job.id\n",
        "while True:\n",
        "    status = client.fine_tuning.jobs.retrieve(job_id)\n",
        "    print(\"Status:\", status.status)\n",
        "    if status.status in [\"succeeded\", \"failed\", \"cancelled\"]:\n",
        "        print(\"Final:\", status)\n",
        "        break\n",
        "    time.sleep(30)\n"
      ],
      "metadata": {
        "id": "DbPvfjJ5LVYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test the model**"
      ],
      "metadata": {
        "id": "KcO-xeLpEG89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ft_model = status.fine_tuned_model\n",
        "completion = client.chat.completions.create(\n",
        "    model=ft_model,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a teaching assistant for Machine Learning.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Explain overfitting.\"}\n",
        "    ]\n",
        ")\n",
        "print(completion.choices[0].message)\n"
      ],
      "metadata": {
        "id": "7Jh1b-5-EOx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***DEPLOYMENT***\n",
        "**Generate  FASTAPI  + dOCKER SET UP**"
      ],
      "metadata": {
        "id": "NZtEyu2SIo0I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.makedirs(\"deployment\", exist_ok=True)\n",
        "\n",
        "with open(\"deployment/app.py\", \"w\") as f:\n",
        "    f.write(f'''\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "from openai import OpenAI\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\"\n",
        "client = OpenAI()\n",
        "app = FastAPI()\n",
        "\n",
        "class Query(BaseModel):\n",
        "    question: str\n",
        "\n",
        "@app.post(\"/ask\")\n",
        "def ask(query: Query):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"{ft_model}\",\n",
        "        messages=[\n",
        "            {{\"role\": \"system\", \"content\": \"You are a teaching assistant for Machine Learning.\"}},\n",
        "            {{\"role\": \"user\", \"content\": query.question}}\n",
        "        ]\n",
        "    )\n",
        "    return {{\"answer\": response.choices[0].message.content}}\n",
        "''')\n",
        "\n",
        "with open(\"deployment/requirements.txt\", \"w\") as f:\n",
        "    f.write(\"fastapi\\nuvicorn\\nopenai\\npydantic\\n\")\n",
        "\n",
        "with open(\"deployment/Dockerfile\", \"w\") as f:\n",
        "    f.write('''\n",
        "FROM python:3.11-slim\n",
        "WORKDIR /app\n",
        "COPY app.py /app\n",
        "COPY requirements.txt /app\n",
        "RUN pip install --no-cache-dir -r requirements.txt\n",
        "EXPOSE 8000\n",
        "CMD [\"uvicorn\", \"app:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n",
        "''')\n",
        "\n",
        "!cd deployment && zip -r deployment_package.zip .\n"
      ],
      "metadata": {
        "id": "HELld41kIshx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download deployment package**"
      ],
      "metadata": {
        "id": "XU5QDGHrMKUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"deployment/deployment_package.zip\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Raz9QJpcJzX_",
        "outputId": "9e034edf-7aaa-46ac-8175-60e7d4be568b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR\u001b[0m:    Error loading ASGI app. Could not import module \"app\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Unzip locally and run this in bash **\n",
        "\n",
        "- docker build -t my-ft-model .\n",
        "- docker run -p 8000:8000 my-ft-model"
      ],
      "metadata": {
        "id": "bS6-C2OcMeNK"
      }
    }
  ]
}